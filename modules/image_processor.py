import cv2
import numpy as np
import torch
from PIL import Image
from matplotlib import pyplot as plt
from segment_anything import sam_model_registry, SamPredictor
from rembg import remove
# from transformers import U2netForPortraitMatting, U2netForPortraitMattingProcessor
# from transformers import AutoProcessor, AutoModel

# --- 1. 初始化模型 ---
# 可以根据你的设备选择 SAM 模型的 checkpoint
# 请从 https://github.com/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb 下载相应的 .pth 文件
# 例如：sam_vit_h_4b8939.pth
SAM_CHECKPOINT = "weights/sam_vit_h_4b8939.pth"
MODEL_TYPE = "vit_h"
device = "cuda" if torch.cuda.is_available() else "cpu"

sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT)
sam.to(device=device)
sam_predictor = SamPredictor(sam)

# 初始化抠图模型
# 可以使用 Hugging Face 的 U-2-Net

# matting_processor = AutoProcessor.from_pretrained("BritishWerewolf/U-2-Net")
# matting_model = AutoModel.from_pretrained('BritishWerewolf/U-2-Net', dtype = 'fp32')
# matting_model.to(device)

def show_mask(mask, ax, random_color=False):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)


def show_points(coords, labels, ax, marker_size=375):
    pos_points = coords[labels == 1]
    neg_points = coords[labels == 0]
    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white',
               linewidth=1.25)
    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white',
               linewidth=1.25)

def get_roi_from_sam(image_path: str):
    """
    使用 SAM 模型进行交互式 ROI 框选。
    左键点击添加前景点，右键点击添加背景点。
    """
    image_bgr = cv2.imread(image_path)
    if image_bgr is None:
        print(f"Error: Unable to read image from {image_path}")
        return None, None

    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    sam_predictor.set_image(image_rgb)

    input_points = []
    input_labels = []

    # todo: 防止图像尺寸过大超出屏幕范围，需要进行缩放显示，同时保证鼠标点击区域对应
    def on_mouse_click(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN or event == cv2.EVENT_RBUTTONDOWN:
            if event == cv2.EVENT_LBUTTONDOWN:
                input_points.append([x, y])
                input_labels.append(1)  # 前景点
            else:
                input_points.append([x, y])
                input_labels.append(0)  # 背景点

            # 在一个副本上绘制所有点，避免覆盖
            image_with_points = param['image'].copy()
            for i, (px, py) in enumerate(input_points):
                color = (0, 255, 0) if input_labels[i] == 1 else (0, 0, 255)
                cv2.circle(image_with_points, (px, py), 5, color, -1)

            cv2.imshow("Select ROI (Left: FG, Right: BG)", image_with_points)

    image_display = image_bgr.copy()
    cv2.imshow("Select ROI (Left: FG, Right: BG)", image_display)
    cv2.setMouseCallback("Select ROI (Left: FG, Right: BG)", on_mouse_click, param={'image': image_bgr})
    key = cv2.waitKey(0)
    cv2.destroyAllWindows()

    if key == ord('s') or key == ord('S'):
        if input_points:
            input_points_np = np.array(input_points)
            input_labels_np = np.array(input_labels)

            # 使用 SAM 生成掩码
            masks, scores, _ = sam_predictor.predict(
                point_coords=input_points_np,
                point_labels=input_labels_np,
                multimask_output=True,
            )

            # 如果没有生成任何掩码，则返回None
            if len(masks) == 0:
                print("No mask generated by SAM.")
                return None, None

            # 找到得分最高的掩码
            id = np.argmax(masks)
            best_mask = masks[np.argmax(scores)]

            print(best_mask.shape)

            plt.figure(figsize=(15, 15))
            plt.imshow(image_rgb)
            show_mask(best_mask, plt.gca())
            show_points(input_points_np, input_labels_np, plt.gca())
            plt.title("SAM Segmentation Result", fontsize=18)
            plt.axis('off')
            plt.show()

            # --- Fix: Resize the mask to match the original image dimensions ---
            # The original image dimensions are image_rgb.shape[1] (width) and image_rgb.shape[0] (height)
            # mask_resized = cv2.resize(best_mask.astype(np.uint8),
            #                           (image_rgb.shape[1], image_rgb.shape[0]),
            #                           interpolation=cv2.INTER_NEAREST)
            # mask_resized = mask_resized.astype(bool)
            #
            # # --- Use the resized mask for visualization ---
            # mask_image = np.zeros_like(image_rgb, dtype=np.uint8)
            # mask_image[mask_resized] = [0, 255, 0]  # Use the resized mask
            #
            # # 创建一个半透明的覆盖层
            # alpha = 0.5
            # visualized_result = cv2.addWeighted(image_rgb, 1 - alpha, mask_image, alpha, 0)
            #
            # # 在可视化图像上绘制输入点
            # for i, (px, py) in enumerate(input_points):
            #     color = (0, 255, 0) if input_labels[i] == 1 else (0, 0, 255)
            #     cv2.circle(visualized_result, (px, py), 5, color, -1)
            #
            # cv2.imshow("SAM Segmentation Result", cv2.cvtColor(visualized_result, cv2.COLOR_RGB2BGR))
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()
            # --- 可视化部分结束 ---

            # 找到掩码的最小包围框作为 ROI
            y_coords, x_coords = np.where(best_mask)
            if y_coords.size > 0 and x_coords.size > 0:
                ymin, ymax = np.min(y_coords), np.max(y_coords)
                xmin, xmax = np.min(x_coords), np.max(x_coords)
                roi_box = (xmin, ymin, xmax, ymax)
                return roi_box, best_mask
            else:
                print("No mask found, please try again.")
                return None, None

    return None, None


def extract_elements(image: np.ndarray, mask: np.ndarray):
    """
    使用深度学习抠图模型，从 ROI 中提取元素。
    """
    # 裁剪 ROI 区域
    ymin, ymax = np.min(np.where(mask)[0]), np.max(np.where(mask)[0])
    xmin, xmax = np.min(np.where(mask)[1]), np.max(np.where(mask)[1])

    roi_image = image[ymin:ymax, xmin:xmax]
    roi_mask = mask[ymin:ymax, xmin:xmax]

    # 转换为 PIL Image
    pil_image = Image.fromarray(cv2.cvtColor(roi_image, cv2.COLOR_BGR2RGB))

    # rembg for background removal
    output_image = remove(pil_image, alpha_matting_foreground_threshold=220)
    extracted_element = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGB2BGRA)

    # todo: 直接使用SAM分割的结果，rembg的结果会导致抠图程度过深，丢失细节

    # # 使用抠图模型进行处理
    # inputs = matting_processor(images=pil_image, return_tensors="pt").to(device)
    # with torch.no_grad():
    #     outputs = matting_model(**inputs)

    # alpha_channel = outputs.alphas
    # # 将 alpha 通道从张量转换为 numpy 数组并调整大小
    # alpha_channel_np = alpha_channel.squeeze().cpu().numpy()
    # alpha_channel_np = (alpha_channel_np * 255).astype(np.uint8)
    #
    # # 创建一个 4 通道的图像 (RGB + Alpha)
    # extracted_element = cv2.cvtColor(roi_image, cv2.COLOR_BGR2BGRA)
    # extracted_element[:, :, 3] = alpha_channel_np

    return extracted_element


def process_image(image_path: str, output_path: str = "output.png"):
    """
    主处理函数。
    """
    print("Step 1: Selecting ROI using SAM...")
    roi_box, mask = get_roi_from_sam(image_path)

    if roi_box and mask is not None:
        print("ROI selected.")
        image = cv2.imread(image_path)

        print("Step 2: Extracting elements using deep learning matting model...")
        extracted_element = extract_elements(image, mask)

        if extracted_element is not None:
            # 保存抠出的元素为 PNG 格式，以支持透明度
            cv2.imwrite(output_path, extracted_element)
            print(f"Successfully extracted and saved to {output_path}")

            # 可视化结果
            cv2.imshow("Extracted Element", extracted_element)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
    else:
        print("ROI selection failed or was cancelled.")


if __name__ == "__main__":
    # 使用示例
    # 请将 'path/to/your/drawing.jpg' 替换为你自己的图像路径
    process_image('datasets/test/drawing_0006.png', 'output/output.png')
